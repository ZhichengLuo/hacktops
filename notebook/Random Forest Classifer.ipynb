{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV\n",
    "\n",
    "from typing import List\n",
    "from typing import Union\n",
    "from typing import Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SHIFT_STEP = 3\n",
    "NB_SAMPLES = SHIFT_STEP * 5\n",
    "WINDOW_LENGTH = 30\n",
    "DILATION_RATIO = 1.5\n",
    "\n",
    "def get_well_relevant_windows(top_index: int, df_well: pd.DataFrame, nb_samples: int=NB_SAMPLES,\n",
    "                              shift: int=SHIFT_STEP, ratio: Union[None, float]=None) -> Tuple[List[np.ndarray], List[np.ndarray]]:\n",
    "    \"\"\"\n",
    "    Given df_well : 'wellName', 'DEPTH', 'GR' and top_index the position of a top in df_well\n",
    "    Returns a list of numerous windows around top_index, and their label\n",
    "    Labels are either True or False\n",
    "    for a given selected window it is labelled True if the distance between its center and\n",
    "    the top position is less than 4\n",
    "\n",
    "    :param top_index: int\n",
    "    :param df_well: pd.DataFrame(columns=['wellName', 'DEPTH', 'GR'])\n",
    "    :param nb_samples: int\n",
    "    :param shift: int=SHIFT_STEP\n",
    "    :param ratio: Union[None, float]=None\n",
    "    :return: list\n",
    "    \"\"\"\n",
    "    windows = []\n",
    "    labels = []\n",
    "    positives = 0\n",
    "    negatives = 0\n",
    "    for i in range(top_index - nb_samples, top_index + nb_samples, shift):\n",
    "        left_limit = i - WINDOW_LENGTH\n",
    "        right_limit = i + WINDOW_LENGTH\n",
    "        window_data = list(map(lambda x: np.array([x]), list(df_well['GR'].values[left_limit:right_limit + 1])))\n",
    "        if np.array(window_data).shape != (WINDOW_LENGTH * 2 + 1, 1):\n",
    "            continue\n",
    "        label = abs(df_well['DEPTH'].iloc[i] - df_well['DEPTH'].iloc[top_index]) < 4\n",
    "        if ratio:\n",
    "            if label:\n",
    "                windows.append(np.array(window_data))\n",
    "                labels.append(np.array(label))\n",
    "            elif negatives / max(positives + negatives, 1) < ratio:\n",
    "                pass\n",
    "            else:\n",
    "                windows.append(np.array(window_data))\n",
    "                labels.append(np.array(label))\n",
    "        else:\n",
    "            windows.append(np.array(window_data))\n",
    "            labels.append(np.array(label))\n",
    "\n",
    "        if label:\n",
    "            positives += 1\n",
    "        else:\n",
    "            negatives += 1\n",
    "\n",
    "    return windows, labels\n",
    "\n",
    "\n",
    "# TODO: check index and len depth\n",
    "\n",
    "def generate_top_dataset(df_logs: pd.DataFrame, df_tops: pd.DataFrame,\n",
    "                         top: str='CONRAD', ratio: Union[None, float]=None):\n",
    "    \"\"\"\n",
    "    From df_logs and df_tops for each well\n",
    "    return a list of relevant windows from the whole signal of the well and the labels of the windows\n",
    "    a relevant window depend on the top\n",
    "    for more explanation about window selection cf get_well_relevant_windows\n",
    "\n",
    "    df_logs contains : 'wellName', 'DEPTH', 'GR'\n",
    "    df_tops contains a column top\n",
    "\n",
    "    :param df_logs: pd.DataFrame\n",
    "    :param df_tops: pd.DataFrame\n",
    "    :param top: str='CONRAD'\n",
    "    :param ratio: Union[None, float]=None\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    windows = []\n",
    "    labels = []\n",
    "    for well_name in df_logs['wellName'].drop_duplicates().tolist():\n",
    "        df_well = df_logs[df_logs['wellName'] == well_name]\n",
    "        top_position = df_tops.loc[well_name][top]\n",
    "        if np.isnan(top_position):\n",
    "            print(\"NAN FOUND\")\n",
    "            continue\n",
    "        depth_list = list(df_well['DEPTH'].values)\n",
    "        real_top_position = min(df_well['DEPTH'].values,\n",
    "                                key=lambda x: abs(x - top_position))  # SOMETIMES top_position not in df_logs\n",
    "        if abs(real_top_position - top_position) > 3:\n",
    "            print(\"DATA BAD LABELLED\")\n",
    "            continue\n",
    "        top_index = depth_list.index(real_top_position)\n",
    "        windows_, labels_ = get_well_relevant_windows(top_index=top_index, df_well=df_well, shift=1, nb_samples=1 * 100,\n",
    "                                                      ratio=ratio)\n",
    "        windows += windows_\n",
    "        labels += labels_\n",
    "    return windows, labels\n",
    "\n",
    "\n",
    "\n",
    "class TopFinder:\n",
    "    \"\"\"\n",
    "    TopFinder: wrapper for window classifier\n",
    "    \n",
    "    Limitations:\n",
    "    - Work on single one top and assume independence among tops\n",
    "    - Find top by classifying windows extracted from well data and discard\n",
    "      the correlation between windows\n",
    "    - Does not utilize geographical info of wells\n",
    "\n",
    "    Usage example:\n",
    "\n",
    "        >>> model.fit(dataset)\n",
    "        >>> model.evaluate_windows = a_func\n",
    "\n",
    "        >>> top_finder = TopFinder(model, top_name)\n",
    "        >>> top_finder.examine_dataset(df_tops)\n",
    "\n",
    "        >>> predicted_depth = top_finder.find_top(df_well)\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, fitted_window_classifier, top_name):\n",
    "        if fitted_window_classifier.evaluate_windows is None:\n",
    "            raise ValueError(\"fitted_window_classifier has to have function evaluate_windows\")\n",
    "        self.window_classifier = fitted_window_classifier\n",
    "        self.work_on_top = top_name\n",
    "        self.stats = {}\n",
    "\n",
    "    def examine_dataset(self, df_tops:pd.DataFrame):\n",
    "        self.stats['top_depth_max'] = df_tops[self.work_on_top].max()\n",
    "        self.stats['top_depth_min'] = df_tops[self.work_on_top].min()\n",
    "\n",
    "    def extract_window(self, df_well:pd.DataFrame, center_idx, window_length):\n",
    "        left_limit = center_idx - window_length\n",
    "        right_limit = center_idx + window_length\n",
    "        window = df_well.loc[left_limit : right_limit, 'GR'].to_numpy()\n",
    "        return window\n",
    "\n",
    "    def get_candidate_windows(self, df_well:pd.DataFrame):\n",
    "        '''\n",
    "        extra prior knowledge may be used to narrow down the scope of candidates, \n",
    "        e.g. top distribution. \n",
    "\n",
    "        return list of windows. Each window includes the depth of its center & GR data.\n",
    "        '''\n",
    "        max_, min_ = self.stats['top_depth_max'], self.stats['top_depth_min']\n",
    "        center_  = (max_ + min_) / 2\n",
    "        depth_diff_ = max_ - min_\n",
    "        dilated_max_ =  center_ + DILATION_RATIO * depth_diff_ / 2\n",
    "        dilated_min_ =  center_ - DILATION_RATIO * depth_diff_ / 2\n",
    "\n",
    "        windows = []\n",
    "        for idx, row in df_well.iterrows():\n",
    "            if row['DEPTH'] < dilated_max_ and row['DEPTH'] > dilated_min_:\n",
    "                window_depth = row['DEPTH']\n",
    "                window_data = self.extract_window(df_well, idx, WINDOW_LENGTH)\n",
    "                if window_data.shape != (WINDOW_LENGTH * 2 + 1,):\n",
    "                    # print(window_data.shape) \n",
    "                    # It happens when the window gets out of the scope of well depth\n",
    "                    continue\n",
    "                windows.append((window_depth, window_data))\n",
    "        return windows\n",
    "\n",
    "    def select_window(self, windows, scores: np.array):\n",
    "        '''\n",
    "        extra prior knowledge may be used here, e.g. top relationships\n",
    "        '''\n",
    "        index_max = np.argmax(scores, axis=0)\n",
    "        return windows[index_max]\n",
    "\n",
    "    def find_top(self, df_well):\n",
    "        \"\"\"\n",
    "        Step:\n",
    "            1. Extract all candidate windows from the well\n",
    "            2. Evalute each candidate by window classifier\n",
    "            3. Select the best candidate\n",
    "            4. Return its associated depth\n",
    "        \"\"\"\n",
    "        if self.window_classifier is None:\n",
    "            raise Exception(\"window_classifier is not set\")\n",
    "        if df_well.shape[0] == 0:\n",
    "            raise Exception(\"input well has no data\")\n",
    "\n",
    "        self.windows = self.get_candidate_windows(df_well)\n",
    "        print(f'{len(self.windows)} candidate windows')\n",
    "        windows_data = np.array([w[1] for w in self.windows])\n",
    "        self.scores = self.window_classifier.evaluate_windows(windows_data)\n",
    "        selected_window = self.select_window(self.windows, self.scores)\n",
    "        self.top_depth = selected_window[0]\n",
    "\n",
    "        return self.top_depth\n",
    "\n",
    "\n",
    "\n",
    "def get_true_windows(df_logs, df_tops, top_, keep_depth = False):\n",
    "    dataset = generate_top_dataset(df_logs=df_logs, df_tops=df_tops, top=top_)\n",
    "    all_well_names = df_logs['wellName'].unique()\n",
    "    print(f'{len(dataset[0])} windows extracted from {len(all_well_names)} wells')\n",
    "\n",
    "    X = np.array(dataset[0]).squeeze(axis=2)\n",
    "    y = np.array(dataset[1])\n",
    "    \n",
    "    print('X:', X.shape)\n",
    "    print('y:', y.shape)\n",
    "\n",
    "    true_idx = [idx for idx in range(len(X)) if y[idx] == True]\n",
    "    print(f'{len(true_idx)} true windows left')\n",
    "\n",
    "    return X[true_idx]\n",
    "\n",
    "def get_true_depth(wellname, top, df_tops):\n",
    "    return df_tops.loc[wellname, top]\n",
    "\n",
    "\n",
    "def visual_scores(depths, scores, max_score_depth=None, true_depth=None, well_name=None):\n",
    "    data = []\n",
    "    data.append(go.Scatter(x=depths,y=scores))\n",
    "    title = \"Evaluation Score w.r.t depth\"\n",
    "    if well_name:\n",
    "        title += f' [well: {well_name}]'\n",
    "    fig = go.Figure(data=data, layout={'title':title})\n",
    "    if max_score_depth:\n",
    "        fig.add_vline(x=max_score_depth, line_width=2, line_color=\"yellow\", \\\n",
    "            annotation_text='Predicated', annotation_position='top left')\n",
    "    if true_depth:\n",
    "        fig.add_vline(x=true_depth, line_width=2, line_color=\"green\", \\\n",
    "            annotation_text='True', annotation_position='top right')\n",
    "    return fig\n",
    "def instance_norm(sample: np.array):\n",
    "    s = (sample - np.min(sample)) / (np.max(sample) - np.min(sample) + 1)\n",
    "    return s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from plotly.offline import iplot\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tops = ['SYLVAIN', 'MARCEL', 'CONRAD']\n",
    "top_ = 'CONRAD'\n",
    "df_logs_ = pd.read_parquet(\"../data/logs.parquet\")\n",
    "df_loc_ = pd.read_parquet(\"../data/loc.parquet\")\n",
    "df_tops_ = pd.read_parquet(\"../data/tops.parquet\")\n",
    "\n",
    "df_logs_test_ = pd.read_parquet(\"../testdata/logs_50.parquet\")\n",
    "df_loc_test_ = pd.read_parquet(\"../testdata/loc_50.parquet\")\n",
    "df_tops_test_ = pd.read_csv(\"../testdata/tops_50.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = generate_top_dataset(df_logs=df_logs_, df_tops=df_tops_, top=top_)\n",
    "test_dataset = generate_top_dataset(df_logs=df_logs_test_, df_tops=df_tops_test_, top=top_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'train windows {len(train_dataset[0])}')\n",
    "print(f'test windows {len(test_dataset[0])}')\n",
    "\n",
    "X_train = np.array(train_dataset[0]).squeeze(axis=2)\n",
    "y_train = np.array(train_dataset[1])\n",
    "X_test = np.array(test_dataset[0]).squeeze(axis=2)\n",
    "y_test = np.array(test_dataset[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#rfc = RandomForestClassifier(n_estimators=500, max_features = 'auto', max_depth=3, criterion = 'gini',random_state=SEED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 4556\n",
    "rfc = RandomForestClassifier(bootstrap=True,n_estimators=500, max_features = 'log2', max_depth=12, criterion = 'gini', random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit RandomForestClassifier\n",
    "rfc.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the test set labels\n",
    "y_pred = rfc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(classification_report(y_pred,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_windows(self, candidate_windows):\n",
    "    return self.predict_proba(candidate_windows)[:,1]\n",
    "import types\n",
    "rfc.evaluate_windows = types.MethodType(evaluate_windows, rfc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_finder = TopFinder(rfc, top_)\n",
    "top_finder.examine_dataset(df_tops_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_well_names = df_logs_test_['wellName'].unique()\n",
    "print(len(test_well_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "for test_well_name in tqdm(test_well_names):\n",
    "    print(f'well: {test_well_name}')\n",
    "    df_test_well = df_logs_test_[df_logs_test_['wellName'] == test_well_name]\n",
    "    predicted_depth = top_finder.find_top(df_test_well)\n",
    "    true_depth = get_true_depth(test_well_name, top_, df_tops_test_)\n",
    "    result.append([test_well_name, predicted_depth, true_depth])\n",
    "    # print(f'true depth: {true_depth}\\t predicated depth: {predicted_depth}\\t error: {abs(predicted_depth - true_depth)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result = pd.DataFrame(result, columns=['wellName', 'predicated_depth', 'true_depth']).set_index('wellName')\n",
    "df_tops_pred = df_result[['predicated_depth']].rename(columns={'predicated_depth': top_})\n",
    "df_tops_true = df_result[['true_depth']].rename(columns={'true_depth': top_})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hacktops.evaluate import recall_tops\n",
    "\n",
    "recall, mae, df_res = recall_tops(df_tops_true, df_tops_pred, tolerance = 6)\n",
    "print(\"recall {0}, mae {1}\".format(recall,mae))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res.iloc[:,-1:].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objs as go\n",
    "\n",
    "depth = [w[0] for w in top_finder.windows]\n",
    "fig = visual_scores(depth, top_finder.scores, top_finder.top_depth, true_depth, test_well_name)\n",
    "iplot(fig)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
