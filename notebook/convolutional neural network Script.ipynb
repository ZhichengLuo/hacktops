{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import numpy as np\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from typing import Union\n",
    "from typing import Tuple\n",
    "\n",
    "SHIFT_STEP = 3\n",
    "NB_SAMPLES = SHIFT_STEP * 5\n",
    "WINDOW_LENGTH = 30\n",
    "DILATION_RATIO = 1.5\n",
    "\n",
    "def get_well_relevant_windows(top_index: int, df_well: pd.DataFrame, nb_samples: int=NB_SAMPLES,\n",
    "                              shift: int=SHIFT_STEP, ratio: Union[None, float]=None) -> Tuple[List[np.ndarray], List[np.ndarray]]:\n",
    "    \"\"\"\n",
    "    Given df_well : 'wellName', 'DEPTH', 'GR' and top_index the position of a top in df_well\n",
    "    Returns a list of numerous windows around top_index, and their label\n",
    "    Labels are either True or False\n",
    "    for a given selected window it is labelled True if the distance between its center and\n",
    "    the top position is less than 4\n",
    "\n",
    "    :param top_index: int\n",
    "    :param df_well: pd.DataFrame(columns=['wellName', 'DEPTH', 'GR'])\n",
    "    :param nb_samples: int\n",
    "    :param shift: int=SHIFT_STEP\n",
    "    :param ratio: Union[None, float]=None\n",
    "    :return: list\n",
    "    \"\"\"\n",
    "    windows = []\n",
    "    labels = []\n",
    "    positives = 0\n",
    "    negatives = 0\n",
    "    for i in range(top_index - nb_samples, top_index + nb_samples, shift):\n",
    "        left_limit = i - WINDOW_LENGTH\n",
    "        right_limit = i + WINDOW_LENGTH\n",
    "        window_data = list(map(lambda x: np.array([x]), list(df_well['GR'].values[left_limit:right_limit + 1])))\n",
    "        if np.array(window_data).shape != (WINDOW_LENGTH * 2 + 1, 1):\n",
    "            continue\n",
    "        label = abs(df_well['DEPTH'].iloc[i] - df_well['DEPTH'].iloc[top_index]) < 4\n",
    "        if ratio:\n",
    "            if label:\n",
    "                windows.append(np.array(window_data))\n",
    "                labels.append(np.array(label))\n",
    "            elif negatives / max(positives + negatives, 1) < ratio:\n",
    "                pass\n",
    "            else:\n",
    "                windows.append(np.array(window_data))\n",
    "                labels.append(np.array(label))\n",
    "        else:\n",
    "            windows.append(np.array(window_data))\n",
    "            labels.append(np.array(label))\n",
    "\n",
    "        if label:\n",
    "            positives += 1\n",
    "        else:\n",
    "            negatives += 1\n",
    "\n",
    "    return windows, labels\n",
    "\n",
    "\n",
    "# TODO: check index and len depth\n",
    "\n",
    "def generate_top_dataset(df_logs: pd.DataFrame, df_tops: pd.DataFrame,\n",
    "                         top: str='CONRAD', ratio: Union[None, float]=None):\n",
    "    \"\"\"\n",
    "    From df_logs and df_tops for each well\n",
    "    return a list of relevant windows from the whole signal of the well and the labels of the windows\n",
    "    a relevant window depend on the top\n",
    "    for more explanation about window selection cf get_well_relevant_windows\n",
    "\n",
    "    df_logs contains : 'wellName', 'DEPTH', 'GR'\n",
    "    df_tops contains a column top\n",
    "\n",
    "    :param df_logs: pd.DataFrame\n",
    "    :param df_tops: pd.DataFrame\n",
    "    :param top: str='CONRAD'\n",
    "    :param ratio: Union[None, float]=None\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    windows = []\n",
    "    labels = []\n",
    "    for well_name in df_logs['wellName'].drop_duplicates().tolist():\n",
    "        df_well = df_logs[df_logs['wellName'] == well_name]\n",
    "        top_position = df_tops.loc[well_name][top]\n",
    "        if np.isnan(top_position):\n",
    "            print(\"NAN FOUND\")\n",
    "            continue\n",
    "        depth_list = list(df_well['DEPTH'].values)\n",
    "        real_top_position = min(df_well['DEPTH'].values,\n",
    "                                key=lambda x: abs(x - top_position))  # SOMETIMES top_position not in df_logs\n",
    "        if abs(real_top_position - top_position) > 3:\n",
    "            print(\"DATA BAD LABELLED\")\n",
    "            continue\n",
    "        top_index = depth_list.index(real_top_position)\n",
    "        windows_, labels_ = get_well_relevant_windows(top_index=top_index, df_well=df_well, shift=1, nb_samples=1 * 100,\n",
    "                                                      ratio=ratio)\n",
    "        windows += windows_\n",
    "        labels += labels_\n",
    "    return windows, labels\n",
    "\n",
    "\n",
    "\n",
    "class TopFinder:\n",
    "    \"\"\"\n",
    "    TopFinder: wrapper for window classifier\n",
    "    \n",
    "    Limitations:\n",
    "    - Work on single one top and assume independence among tops\n",
    "    - Find top by classifying windows extracted from well data and discard\n",
    "      the correlation between windows\n",
    "    - Does not utilize geographical info of wells\n",
    "\n",
    "    Usage example:\n",
    "\n",
    "        >>> model.fit(dataset)\n",
    "        >>> model.evaluate_windows = a_func\n",
    "\n",
    "        >>> top_finder = TopFinder(model, top_name)\n",
    "        >>> top_finder.examine_dataset(df_tops)\n",
    "\n",
    "        >>> predicted_depth = top_finder.find_top(df_well)\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, fitted_window_classifier, top_name):\n",
    "        if fitted_window_classifier.evaluate_windows is None:\n",
    "            raise ValueError(\"fitted_window_classifier has to have function evaluate_windows\")\n",
    "        self.window_classifier = fitted_window_classifier\n",
    "        self.work_on_top = top_name\n",
    "        self.stats = {}\n",
    "\n",
    "    def examine_dataset(self, df_tops:pd.DataFrame):\n",
    "        self.stats['top_depth_max'] = df_tops[self.work_on_top].max()\n",
    "        self.stats['top_depth_min'] = df_tops[self.work_on_top].min()\n",
    "\n",
    "    def extract_window(self, df_well:pd.DataFrame, center_idx, window_length):\n",
    "        left_limit = center_idx - window_length\n",
    "        right_limit = center_idx + window_length\n",
    "        window = df_well.loc[left_limit : right_limit, 'GR'].to_numpy()\n",
    "        return window\n",
    "\n",
    "    def get_candidate_windows(self, df_well:pd.DataFrame):\n",
    "        '''\n",
    "        extra prior knowledge may be used to narrow down the scope of candidates, \n",
    "        e.g. top distribution. \n",
    "\n",
    "        return list of windows. Each window includes the depth of its center & GR data.\n",
    "        '''\n",
    "        max_, min_ = self.stats['top_depth_max'], self.stats['top_depth_min']\n",
    "        center_  = (max_ + min_) / 2\n",
    "        depth_diff_ = max_ - min_\n",
    "        dilated_max_ =  center_ + DILATION_RATIO * depth_diff_ / 2\n",
    "        dilated_min_ =  center_ - DILATION_RATIO * depth_diff_ / 2\n",
    "\n",
    "        windows = []\n",
    "        for idx, row in df_well.iterrows():\n",
    "            if row['DEPTH'] < dilated_max_ and row['DEPTH'] > dilated_min_:\n",
    "                window_depth = row['DEPTH']\n",
    "                window_data = self.extract_window(df_well, idx, WINDOW_LENGTH)\n",
    "                if window_data.shape != (WINDOW_LENGTH * 2 + 1,):\n",
    "                    # print(window_data.shape) \n",
    "                    # It happens when the window gets out of the scope of well depth\n",
    "                    continue\n",
    "                windows.append((window_depth, window_data))\n",
    "        return windows\n",
    "\n",
    "    def select_window(self, windows, scores: np.array):\n",
    "        '''\n",
    "        extra prior knowledge may be used here, e.g. top relationships\n",
    "        '''\n",
    "        index_max = np.argmax(scores, axis=0)\n",
    "        return windows[index_max]\n",
    "\n",
    "    def find_top(self, df_well):\n",
    "        \"\"\"\n",
    "        Step:\n",
    "            1. Extract all candidate windows from the well\n",
    "            2. Evalute each candidate by window classifier\n",
    "            3. Select the best candidate\n",
    "            4. Return its associated depth\n",
    "        \"\"\"\n",
    "        if self.window_classifier is None:\n",
    "            raise Exception(\"window_classifier is not set\")\n",
    "        if df_well.shape[0] == 0:\n",
    "            raise Exception(\"input well has no data\")\n",
    "\n",
    "        self.windows = self.get_candidate_windows(df_well)\n",
    "        print(f'{len(self.windows)} candidate windows')\n",
    "        windows_data = np.array([w[1] for w in self.windows])\n",
    "        self.scores = self.window_classifier.evaluate_windows(windows_data)\n",
    "        selected_window = self.select_window(self.windows, self.scores)\n",
    "        self.top_depth = selected_window[0]\n",
    "\n",
    "        return self.top_depth\n",
    "\n",
    "\n",
    "\n",
    "def get_true_windows(df_logs, df_tops, top_, keep_depth = False):\n",
    "    dataset = generate_top_dataset(df_logs=df_logs, df_tops=df_tops, top=top_)\n",
    "    all_well_names = df_logs['wellName'].unique()\n",
    "    print(f'{len(dataset[0])} windows extracted from {len(all_well_names)} wells')\n",
    "\n",
    "    X = np.array(dataset[0]).squeeze(axis=2)\n",
    "    y = np.array(dataset[1])\n",
    "    \n",
    "    print('X:', X.shape)\n",
    "    print('y:', y.shape)\n",
    "\n",
    "    true_idx = [idx for idx in range(len(X)) if y[idx] == True]\n",
    "    print(f'{len(true_idx)} true windows left')\n",
    "\n",
    "    return X[true_idx]\n",
    "\n",
    "def get_true_depth(wellname, top, df_tops):\n",
    "    return df_tops.loc[wellname, top]\n",
    "\n",
    "\n",
    "def visual_scores(depths, scores, max_score_depth=None, true_depth=None, well_name=None):\n",
    "    data = []\n",
    "    data.append(go.Scatter(x=depths,y=scores))\n",
    "    title = \"Evaluation Score w.r.t depth\"\n",
    "    if well_name:\n",
    "        title += f' [well: {well_name}]'\n",
    "    fig = go.Figure(data=data, layout={'title':title})\n",
    "    if max_score_depth:\n",
    "        fig.add_vline(x=max_score_depth, line_width=2, line_color=\"yellow\", \\\n",
    "            annotation_text='Predicated', annotation_position='top left')\n",
    "    if true_depth:\n",
    "        fig.add_vline(x=true_depth, line_width=2, line_color=\"green\", \\\n",
    "            annotation_text='True', annotation_position='top right')\n",
    "    return fig\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uploading The datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#uncomment the top to work with one top at a time\n",
    "\n",
    "#top = 'CONRAD' \n",
    "#top = 'SYLVAIN'\n",
    "top = 'MARCEL'\n",
    "df_logs = pd.read_parquet(\"../data/logs.parquet\")\n",
    "df_loc = pd.read_parquet(\"../data/loc.parquet\")\n",
    "df_tops = pd.read_parquet(\"../data/tops.parquet\")\n",
    "\n",
    "df_logs_test = pd.read_parquet(\"../testdata/logs_50.parquet\")\n",
    "df_loc_test = pd.read_parquet(\"../testdata/loc_50.parquet\")\n",
    "df_tops_test = pd.read_csv(\"../testdata/tops_50.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = generate_top_dataset(df_logs= df_logs, df_tops=df_tops, top=top)\n",
    "test_dataset = generate_top_dataset(df_logs=df_logs_test, df_tops=df_tops_test, top=top)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(train_dataset[0]).squeeze(axis=2)\n",
    "y = np.array(train_dataset[1])\n",
    "\n",
    "X_test= np.array(test_dataset[0]).squeeze(axis=2)\n",
    "y_test = np.array(test_dataset[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training set: \", X.shape,y.shape)\n",
    "print(\"Testing set: \", X_test.shape,y_test.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time series to Image Transformation\n",
    "\n",
    "To work with CNN the time series need to be changed data grid-like format, therefore the data will be changed to image format of GASF,GADF and MTF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a method to change timeseries to either Gramian Angular Summation Field (gasf) or Gramian Angular Difference Field (gadf)\n",
    "\n",
    "def gaf(X,method):\n",
    "    from pyts.image import GramianAngularField\n",
    "    transformer = GramianAngularField(method=method)\n",
    "    X_new = transformer.transform(X)\n",
    "    X_new = np.expand_dims(X_new,axis=3)\n",
    "    return X_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a method to change timeseries to Markov Transition Field (MTF)\n",
    "\n",
    "def mtf(X):\n",
    "    from pyts.image import MarkovTransitionField\n",
    "    transformer = MarkovTransitionField()\n",
    "    X_new = transformer.transform(X)\n",
    "    X_new = np.expand_dims(X_new,axis=3)\n",
    "    return X_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a method to change timeseries to the combined format of gasf,gadf and mtf\n",
    "\n",
    "def combined(X):\n",
    "    X_gasf=gaf(X,method='summation')\n",
    "    X_gadf=gaf(X,method='difference')\n",
    "    X_mtf= mtf(X)\n",
    "    X_new=np.concatenate((X_gasf,X_gadf,X_mtf),axis=3)\n",
    "    return X_new"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Caling function for changing the time series to image\n",
    "Make sure to choose one image format for both training and testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#call one funcion at a time\n",
    "#X_new= mtf(X)\n",
    "#X_new= gaf(X,method='summation') #for gasf\n",
    "X_new= gaf(X,method='difference') #for gadf\n",
    "#X_new= combined(X)\n",
    "X_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_test= mtf(X_test)\n",
    "#X_test= gaf(X_test,method='summation') #for gasf\n",
    "X_test= gaf(X_test,method='difference') #for gadf\n",
    "#X_test= combined(X_test)\n",
    "X_test.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize the tranformed timeseries of the first well in a dataset\n",
    "f, axs = plt.subplots(1,2,figsize=(10,10))\n",
    "plt.subplot(2,2,1)\n",
    "plt.title('Timeseries')\n",
    "plt.plot(X[0])\n",
    "plt.subplot(2,2,2)\n",
    "plt.title('Image Transformed')\n",
    "plt.imshow(X_new[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_new, y, test_size=0.33, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training Sets',X_train.shape, y_train.shape)\n",
    "print('Validation Sets',X_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model training \n",
    "model = Sequential()\n",
    "#add model layers\n",
    "model.add(Conv2D(64, kernel_size=3, activation='sigmoid', input_shape=X_train.shape[1:]))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv2D(32, kernel_size=3, activation='sigmoid'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(2, activation='sigmoid'))\n",
    "\n",
    "#compile model using accuracy to measure model performance\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "callback = EarlyStopping(monitor='val_loss',patience=3, restore_best_weights=True)\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=10, callbacks=callback)\n",
    "\n",
    "#load mtf for conrad\n",
    "#model= load_model('model/conrad/mtf/model.h5')\n",
    "\n",
    "#model.save_weights('model/conrad/mtf/weights.h5')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the model for future use!\n",
    "Each model is for a specific top and a specific image format, therefore it will be 3X4=12 saved models, meaning 3 tops and 4 images format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Uncomment one of the below lines of code to save the model based on the choosen image format\n",
    "\n",
    "#FOR CONRAD\n",
    "#model.save('model/conrad/mtf/model.h5')\n",
    "#model.save('model/conrad/gasf/model.h5')\n",
    "#model.save('model/conrad/gadf/model.h5')\n",
    "#model.save('model/conrad/combined/model.h5')\n",
    "\n",
    "#FOR MARCEL\n",
    "#model.save('model/marcel/mtf/model.h5')\n",
    "#model.save('model/marcel/gasf/model.h5')\n",
    "#model.save('model/marcel/gadf/model.h5')\n",
    "#model.save('model/marcel/combined/model.h5')\n",
    "\n",
    "#FOR SYLVAIN\n",
    "#model.save('model/sylvain/mtf/model.h5')\n",
    "#model.save('model/sylvain/gasf/model.h5')\n",
    "#model.save('model/sylvain/gadf/model.h5')\n",
    "#model.save('model/sylvain/combined/model.h5')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction Results Summmary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score,cohen_kappa_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.argmax(model.predict(X_test), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# accuracy: (tp + tn) / (p + n)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy: %f' % accuracy)\n",
    "\n",
    "# precision tp / (tp + fp)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "print('Precision: %f' % precision)\n",
    "\n",
    "# recall: tp / (tp + fn)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "print('Recall: %f' % recall)\n",
    "\n",
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print('F1 score: %f' % f1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print('Prediction Accuracy Score {:.2f}.'.format(accuracy_score(y_test,y_pred)))\n",
    "clax_report = classification_report(y_test,y_pred,output_dict=True)\n",
    "report_df = pd.DataFrame(clax_report).transpose()\n",
    "report_df\n",
    "\n",
    "print('Training Process Completed')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TESTING START HERE!\n",
    "In the below code of lines is for testing the how to extract a specific depth where the top is found!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from hacktops.model import TopFinder\n",
    "#from hacktops.utils import get_true_windows\n",
    "#from hacktops.settings import WINDOW_LENGTH\n",
    "from plotly.offline import iplot\n",
    "from tqdm import tqdm\n",
    "#from hacktops.utils import get_true_depth, visual_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_windows(self, candidate_windows):\n",
    "    #well= mtf(candidate_windows)\n",
    "    #well= gaf(candidate_windows,method='summation')\n",
    "    well= gaf(candidate_windows,method='difference')\n",
    "    #well= combined(candidate_windows)\n",
    "    return self.predict(well)[:,1]\n",
    "import types\n",
    "model.evaluate_windows = types.MethodType(evaluate_windows, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_finder = TopFinder(model, top)\n",
    "top_finder.examine_dataset(df_tops) #what is this top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_well_names = df_logs_test['wellName'].unique()\n",
    "print(len(test_well_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "for test_well_name in tqdm(test_well_names):\n",
    "    # print(f'well: {test_well_name}')\n",
    "    df_test_well = df_logs_test[df_logs_test['wellName'] == test_well_name]\n",
    "    predicted_depth = top_finder.find_top(df_test_well)\n",
    "    true_depth = get_true_depth(test_well_name, top, df_tops_test)\n",
    "    result.append([test_well_name, predicted_depth, true_depth])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result = pd.DataFrame(result, columns=['wellName', 'predicated_depth', 'true_depth']).set_index('wellName')\n",
    "df_tops_pred = df_result[['predicated_depth']].rename(columns={'predicated_depth': top})\n",
    "df_tops_true = df_result[['true_depth']].rename(columns={'true_depth': top})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hacktops.evaluate import recall_tops\n",
    "\n",
    "recall, mae, df_res = recall_tops(df_tops_true, df_tops_pred, tolerance = 4)\n",
    "print(\"recall {0}, mae {1}\".format(recall,mae))\n",
    "df_res.head(50)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizing a well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth = [w[0] for w in top_finder.windows]\n",
    "fig = visual_scores(depth, top_finder.scores, top_finder.top_depth, true_depth, test_well_name)\n",
    "iplot(fig)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
